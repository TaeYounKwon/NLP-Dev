원-핫 인코딩 설명

먼저, 단어집합이란?
- 서로 다른 단어들의 집합
- book 와 books 같은 단어의 변형 형태도 다른 단어로 간주
- 원-핫 인코딩을 하기 위해서는 먼저 단어 집합을 만들어야함
- 텍스트의 모든 단어를 중복을 허용하지 않고 뫃아놓은 것
- 이 단어 집합에 고유한 정수를 부여하는 정수 인코딩을 진행
- 겹치지 않는 단어가 500개가 있다면, 단어집합의 크기또한 500. 
- 이제 이 숫자로 바뀐 단어들을 벡터로 다루고 싶어서 나온 것이 원-핫 인코딩

원-핫 인코딩이란?
- 단어 집합의 크기를 벡터의 차원으로 하고, 표ㅛ현하고 싶은 단어의 인덱스에 1의 값을 부여
- 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식 -> 원 핫 벡터

원 핫 인코딩의 두 과정
- 정수 인코딩을 수행(각 단어에 고유한 정수를 부여)
- 표현하고 싶은 단어의 고유한 정수를 인덱스로 간주, 해당 위치에 1을 부여
- 다른 단어의 인덱스의 위치에는 0을 부여

원 핫 인코딩의 한계
- 단어의 개수가 늘어날수록, 벡터를 저장하기 위해 필요한 공간이 증가
-> 다른 말로 벡터의 차원 증가
-> 공간적 측면으로는 매우 비효율적임
- 단어의 유사도를 표현할 수 없음
-> 개, 늑대, 고양이, 호랑이 등 비슷한 특징이 있는 단어라도 그 유사성을 표현 할 수 없음
-> 이건 결국, 검색 시스템등에서도 활용될 수 없음
--> 예를 들면, 시애틀 숙소를 쳤을 때, 시애틀 호텔, 시애틀 숙박 등의 결과물이 나오지 않게됨

해결방안
-  LSA(잠재 의미 분석)
-> 카운트 기반의 벡터화
-> HAL 등
- NNLM, RNNLM, Word2Vec, FastText
-> 예측 기반
- Glove
-> 카운트와 예측 기반 두 가지 방법을 모두 사용
- 워드 임배딩 단원에서 더 자세히!


 