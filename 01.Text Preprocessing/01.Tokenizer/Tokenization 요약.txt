토큰화(Tokenization)요약


Intro
크롤링 등으로 얻어낸 코퍼스 데이터가 데이터 필요에 맞게 전처리 되지않았다면
- 여기서 코퍼스란? -> 말뭉치, 여러 단어들로 이루어진 문장
- 해당 데이터를 사용하고자 하는 용도에 맞게 토큰화, 정제, 정규화 작업을 실시
- 이번 실습은 여기서 토큰화(tokenization)에 대해

단어 토큰화(Word Tokenization)
- 일단 토큰이란? 보통 의미있다고 생각되는 단어나 문장(여기에서는 단어)
- 단어 토큰화는 일반적으로 구두점(".", ",", "!", "?", ";"등의 기호)을 제거한 뒤 
- 뛰어쓰기(white-space)를 기준으로 토큰화 작업을 시작
- 방법들로는 nltk.tokenize에서 word_tokenize / wordPunctTokenizer

문제점 발생
- Don't라던가, Jack's 라던가, Ph.D, AT&T등 뜻을 지칭하는 알파벳 사이에 구두점이 포함되는 경우가 다수 존재

해결 방안?
- ' 를 제외한 구두점 제거!: tensorflow.keras.preprocessing.text import text_to_word_sequence
- 표준으로 쓰이고 있는 토큰화 방법 중 하나인 "Penn Treebank Tokenization" 규칙 사용

Penn Treebank Tokenization이란
- 하이푼으로 구성된 단어는 하나로 유지한다
- doesn't와 같이 아포스트로피로 '접어'가 함꼐하는 단어는 분리해준다
- nltk.tokenize에서 TreebankWordTokenizer방법 사용
- 사용 시, home-base, does, n't 식으로 분리됨 

문장 토큰화(Sentence Tokenization)
- 간단히 마침표나 느낌표, 물음표 등으로만 문장을 구분할 수는 없음
-> IP 192.168.56.31 서버에 들어가서 결과를 aaa@gmail.com로 보내줘. <-이런식의 문장들 때문에
- nltk.tokenize에서 sent_tokenize 사용하면 영어 문장과 관련해서는 문장 토큰화를 잘 해내는걸 확인 할 수 있음
- 한국 문장의 경우에는 kss 라이브러리를 설치하여 사용

한국 문장 토큰화의 어려움 
- 한국어에서는 주어뒤에 조사(예: 그가, 그를, 그에게ㅡ 그와, 그는 등)가 붙는데...
- 이를 간단히 뛰어쓰기 토큰화(어절 토큰화) 시키면 단어 토큰화와 거의 같지 않음. 
- 영어보다 한국어는 띄어쓰기가 잘 지켜지지 않음
-> 잭이글을이렇게적어도이해가가잖아요!
-> eventhoughiwritelikethispeoplestillcanunderstand!

한국어 토큰화를 위해서는....
- 형태소(morpheme)란 개념을 반드시 이해해야함
- 형태소란 뜻을 가진 가장 작은 말의 단위
-> 자립형태소: 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소
-> 의존 형태소: 다른 형태소와 결합하여 사용되는 형태소
-> 예) 잭이 책을 읽었다
--> 형태소 토큰화: 자립형태소(에디,책), 의존형태소(-가,-을,읽-,-었,-다)
--> 어절토큰화: 띄어쓰기 단위 토큰화(에디가, 책을, 읽었다)

품사 태깅(Part-of-speech tagging)
- 하나의 단어가 각 문장에서 다른 뜻을 의미하는 것
- 예) fly - 날다(v), 파리(n) 
- 영문의 경우 nltk.tag에서 pos_tag를 사요하여 품사 태깅 사용가능. 
- 한국어의 경우 KoNLPy에서 형태소 분석기(Okt, Kkma)를 사용하여 형태소 분석 가능
-> 실습 후
--> 띄어쓰기가 되어있는 경우와 되어있지 않은 경우의 결과가 다른게 몇개 추출됨
--> Okt보단 Kkma의 형태소 분석이 조금 더 잘 되는 것을 확인
--> 뭔가 두개의 결과물을 합친다면 조금 더 괜찮은 모델이 나올지도...?


