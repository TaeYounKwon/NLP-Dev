로지스틱 회기(Logistic Regression)요약

이진 분류(Binary Classification)란?
- 둘 중 하나의 선택지 중에서 정답을 고르는 것
- 예로 일정 성적 이상부터 합격/불합격을 따지는 문제
- 여기서 y=wx+b의 직선을 사용하면 안좋은 이유?
-> y값이 음의 무한대부터 양의 무한대와 같은 큰 수들도 가질 수 있는데 문제 자체가 그렇지 않음
- 합격/불합격을 0과 1로만 표현하고 60점 이상부터 합격이라면
-> 그래프가 55점 아래에서는 0, 60점 이상부터 합격인 1로 표현될 수 있는데
-> 이때, 그래프는 0과 1사이의 값을 가지면서 S자 형태로 그려지게 됨

시그모이드 함수(Sigmoid Function)
- 출력이 0과 1사이의 값을 가지면서 S자 형태로 그려지는 함수
- x가 감소하면 0에 수렴, 0일 때눈 0.5, x가 증가하면 1에 수렴
- 식은 H(x) = 1/(1+e^-(wx+b)) = sigmoid(wx+b) = theta(wx+b)로 나타나짐
- 여기서 구해야할 것은 여전히 주어진 데이터에 가장 적합한 가중치 w와 편향 b
- 가중치 w와 편향 b 가 어떤 영향을 미치는지는 실습에서 확인!
-> 가중치가 늘어나고 줄어듬에 따라 그래프의 경사(기울기)가 바뀜
-> 편향이 늘어나고 줄어듬에 따라 좌 우로 이동 
- 이를 통해
-> 출력값이 0.5 이상이면 1(True), 0.5이하면 0(False)로 만들어 이진 분류 문제를 풀기 위해 사용 가능

비용 함수(Cost Function)
- 로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 w를 찾아냄
- BUT! 비용 함수로 평균 제곱 오차를 사용하지 않음
-> 왜? 로지스틱 회귀에서 MSE를 사용하게 되면 로컬 미니멈에 빠질 가능성이 높음
-> 로컬 미니멈? 
--> 특정 구역에서의 최솟값, 전체 함수에 걸쳐 최소값인 글로벌 미니멈이 아닌 특정 구역내의 최소값인 로컬 미니멈값
- 그럼 비용함수로 뭘 써야 합니까??
-> 크로스 엔트로피 함수요!

크로스 엔트로피의 개념을 하나씩 쌓아봅시다.
- 일단 평균 제곱오차와 비슷하게 식을 천천히 쌓아보자면
- 목적함수 J(w) = 1/n(평균을 낼꺼고) * K(x)
- K(x) = 각 오차를 더해주는 함수 ( f( H(x), y) ) )
- f(x) = 실제값 y와 예측값 H(x)의 오차를 나타내는 함수
- 여기서 목표는 함수 f를 어떻게 정의하느냐! 
- 목적 함수(J(w))는 전체 데이터에 대해서 어떤 함수 f의 값의 평균을 계산하는 중이고
- 적절한 가중치를 찾기 위해서 결과적으로 실제값과 예측값에 대한 오차를 줄여야 하므로 f를 비용함수로 지정
-> J(w) = 1/n K( cost(H(x), y) ) f->cost로 바뀜
- 시그모이드 함수는 0과 1 사이의 y값을 반환
-> 이는 실제값이 0일때 y값이 1에 가까워지면 오차가 커짐
--> if y=0 -> cost(H(x),y) = -log(1-H(x))
-> 실제값이 1일때 y값이 0에 가까워지면 오차가 커짐
--> if y=1 -> cost(H(x), y) = -log(H(x))
-> 이를 한 식으로 표현하자면
--> cost(H(x),y) = -[ylogH(x) + (1-y)log(1-H(x))]
--> y와 (1-y)가 식 중간에 들어갔고, 두개의 식을 -로 묶음
--> 이 식을 K(x)안에 넣어주면 됨
- 크로스 엔트로피는 소프트맥스 회귀의 비용함수이므로 뒤에서 재언급됨


