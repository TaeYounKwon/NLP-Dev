머신러닝 요약

머신러닝이 필요한 이유?
- 기존 프로그렘들은 데이터(input)을 넣으면 그에 따른 해답(output)이 나오는 형태로 개발
- 그러나 주어진 사진이 고양이인지 강아지인지 판별하는 코드를 개발할 때에는 위의 방법으로는 해결 불가
-> 왜? 사진을 구별하는 명확한 알고리즘이 없기 때문에
-> 이미 이미지 내의 경계선과 같은 것들을 찾아내서 알고리즘화 하려고 해봤지만...
-> 특징을 잡아내는 것에 한계가 있었음

머신러닝은 기존 프로그렘과 어떻게 다른가?
- 머신러닝은 데이터가 주어지면, 기계가 스스로 데이터로부터 규칙성을 찾는 것에 집중
-> 이 과정을 우리는 훈련(training) 또는 학습(learning)이라고 함

머신러닝 모델의 평가
- 기존에 train, test로 나눈 데이터를...
-> Validation으로도 나눠서 데이터를 3가지로 분리시키는 것이 일반적
- 왜 Validation이 필요한가??
-> 모델이 훈련 데이터에 과적합(overfitting)되는지 확인하려고
-> 과적합은 아래에 더 자세한 설명
- 하이퍼파라미터(초매개변수): 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수
- 매개변수: 가중치와 편향, 학습하는동안 값이 계속해서 변하는 수
- 모델 트레이닝이 끝나면 검증용 데이터를 사용해서 정확도를 검증하며 하이퍼파라미터를 튜닝(tuning)함
-> 검증용 데이터에 대해서 높은 정확도를 얻도록 하이퍼 파라미터의 값을 바꿔보는 것

분류(Classification)와 회기(Regression)
- 이진 분류 문제(Binary Classification)
-> 주어진 입력에 대해서 두개의 선택지 중 하나의 답을 선택해야하는 경우
-> 시험의 합격/불합격, 정상메일/스펨메일, 개/고양이

- 다중 클래스 분류(Multi-class Classification)
-> 주어진 입력에 대해서 3개 이상의 선택지 중에서 답을 선택해야 하는 경우
-> 사진이 짜장면, 짬뽕, 탕수육 중 어느 카테고리에 들어가는지 고르는것

-회귀 문제(Regression)
-> 몇개의 정해진 선택지 중에서 정답을 찾아내는 것이 아닌
-> 어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우
-> 기존의 분류 문제와 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가지는 문제
-> 시계열 데이터를 이용한 주가 예측, 생산량 예측 등

지도 학습과 비지도 학습
- 지도학습(Supervised Learning)
-> 지도학습이란 레이블(Label)이라는 정답과 함께 학습하는 것
-> 자연어 처리는 대부분 지도 학습에 속함

- 비지도 학습(Unsupervised Learning)
-> 데이터에 별도의 레이블이 없이 학습하는 것
-> 텍스트 처리 분야의 토픽 모델링 알고리즘인 LSA나 LDA는 비지도 학습

- 자기지도 학습(Self-Supervised Learning, SSL)
-> 레이블이 없는 데이터가 주어지면, 모델이 학습을 위해서 스스로 데이터로부터 레이블을 만들어서 학습
-> Word2Vec과 같은 워드 임베딩 알고리즘
-> BERT와 같은 언어 모델의 학습 방법

샘플(Sample)과 특성(Feature)
- 데이터를 나눌 때에 x를 가지고 y를 예측한다면...
-> 머신 러닝에서는 하나의 데이터, 행렬 관점에서는 하나의 행(첫줄, 둘째 줄 등)을 샘플(sample)이라고 부름
-> 데이터베이스에서 레코드(record)라고 부르는 단위
-> 종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성(Feature)라고 부름, 행렬관점에서는 각 열

혼동 행렬(Confusion Matrix)
-머신 러닝에서 정확도(Accuracy)란?
-> 정확도 = 맞춘 문제수 / 전체 문제수
- 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지 x
- 이럴 때 더 정확한 데이터 확인을 위해 사용하느 것이 혼동 행렬
- 아래 4가지 케이스를 정의
-> True Positive(TP): 실제 True인 정답을 True라고 예측 (정답)
-> False Positive(FP): 실제 False인 정답을 True라고 예측 (오답)
-> False Negative(FN): 실제 True인 정답을 False라고 예측(오답)
-> True Negative(TN): 실제 False인 정답을 False라고 예측(정답)
- 이 개념을 사용하면 정밀도(Precision)과 재현율(Recall)을 구할 수 있음
- 정밀도와 재현율 모두 실제 True인 정답을 모델이 True라고 예측한 경우, 즉, TP에 관심이 있음

- 정밀도(Precision)란?
-> 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율
-> 계산식: 정밀도 = TP/(TP+FP)

- 재현율(Recall)이란?
-> 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율
-> 계산식: 재현율 = TP/(TP+FN)

- 정확도(Accuracy)란?
-> 전체 예측한 데이터 중에서 정답을 맞춘 것에 대한 비율
-> 계산식: 정확도 = (TP+TN)/(TP+FP+TN+FN)
-> 일반적으로 실생활에서도 가장 많이 사용하는 지표
-> 그러나 Accuracy로 성능을 예측하는 것이 안좋을 경우가 있음
--> 예) 비가 오는 날을 예측하는 모델
--> 97일동안 비가 내리지 않는 것을 예측
--> 3일동안 비가 내리는 것을 예측하지 못함
--> Accuracy = 97% 하지만, 사실상 비가 오는 것을 예측하지 못하는 모델일 수도 있음
-> 실질적으로 더 중요한 경우에 대한 데이터가 전체 데이터에서 너무 적은 비율을 차지할 때
-> 정확도는 좋은 측정 지표가 될 수 없음
-> 이런 경우에는 F1-Score를 사용 

과적합(Overfitting)과 과소적합(Underfitting)
- 과적합이란?
-> 훈련 데이터를 과하게 학습한 경우
-> 예) 시험을 위해 공부할 때, 족보를 달달 외웠지만, 정작 시험에서 족보에 없는 문제를 보고 틀리고 말았다.
-> 훈련데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 커짐
-> 오차 그래프를 그려서 확인하자면
-> y축에 오차(loss), x축에 에포크(epoch)를 두고 오차 그래프를 그리게 되는데...
--> 여기서 에포크란? - 전체 훈련 데이터에 대한 훈련 횟수
--> 사람으로 비유하면 동일한 문제지를 반복해서 푼 횟수
-> 해결 방안? 드롭 아웃(Dropout), 조기 종료(Early Stopping)과 같은 방법(추후 설명)

- 과소적합이란?
-> 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태
-> 훈련 자체가 부족한 상태이므로 훈련 횟수인 에포크가 지나치게 적으면 발생할 수 있음
-> 테스트 데이터 뿐만 아니라 훈련 데이터에 대해서도 정확도가 낮은 상태

- 머신 러닝에서 학습 이나 훈련이라고 하는 과정을 적합(fitting)이라고 부르기에 위의 단어가 나옴

현업에서는 어떻게 위의 문제를 해결하는가?
- 테스트 데이터를 2개로 나눔
-> 과적합 모니터링과 하이퍼파라미터 튜닝을 위한 테스트 데이터
-->> 검증 데이터라고도 부름
-> 오직 성능 평가만을 위한 테스트 데이터

현업에서의 딥 러닝 모델의 학습 과정
- step1. 주어진 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나눈다.(대략, 6:2:2)
- step2. 훈련 데이터로 모델을 학습한다.( 에포크+1)
- step3. 검증 데이터로 모델을 평가하여 검증 데이터에 대한 정확도와 오차(loss)를 계산한다
- step4. 검증 데이터의 오차가 증가하였다면 과적합 징후이므로 학습 종료 후, step 5나 step 2로 재이동
- step5. 모델의 학습이 종료되었으니 테스트 데이터로 모델을 평가 