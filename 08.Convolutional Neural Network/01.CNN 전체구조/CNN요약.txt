합성곱 신경망(Convolutional Neural Network, CNN) 요약

CNN이란?
- 이미지 인식과 음성 인식 등 다양한 곳에서 사용
- 기존 Affine-ReLU으로만 이루어진 완전연결 계층에서 합성곱(ConV)계층과 풀링(Pooling)계층이 추가된 것
-> 기존: Affine-ReLU -> Affine-ReLU-> Affine-Softmax 였다면
-> 현재: Conv-ReLU-Pooling-> Conv-ReLU-> Affine-ReLU ->Affine-Softmax로 바뀌는 것

완전연결 계층의 문제점
- 데이터의 형상이 무시됨
- 평탄화 작업(3차원->1차원 등)을 거치면서 색이나 모양등의 데이터가 사라지게 됨
-> 공간적으로 가까운 픽셀의 값, RGB의 밀접성, 거리가 먼 픽셀과의 연관성 등이 무시가 되게 됨

합성곱 계층은 뭐가 다른가?
- 형상을 유지, 3차원 데이터로 입력받으며 다음 계층에도 3차원 데이터로 전달
- 입출력 데이터를 특징 맵(Feature Map)이라고 부름
- 입력/출력 특징 맵
- 들어오는 입력 데이터에 필터(커널)를 적용
- 합성곱 여산은 필터의 윈도우를 일적 간격으로 이동해가며 입력 데이터에 적용
-> 예) 데이터가 4x4고 필터가 3x3이라면 좌상,우상,좌하,우하로 4번 돌며 2x2의 결과물을 도출해 냄
- 필터의 매개변수 = 완전연결 신경망의 가중치 w
- 편향은 "항상" 1x1의 크기로 입력데이터 x 필터의 결과물의 각 원소에 다 더해짐 

패딩과 스트라이드
- 패딩이란?
- 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우는 것
-> 예) 입력 데이터가 3x3이라면, 주변의 데이터를 0,1, 혹은 임의의 특정 값으로 채워 5x5로 만들어 주는 것
- 입력의 크기 = 입력의 크기 + (패딩의 크기 x 2)
-> 패딩의 크기 또한 1이상으로 다양하게 걸어 줄 수 있음
- 패딩을 키우면 출력 크기가 커짐

- 스트라이드란?
- 필터를 적용하는 위치의 간격
- 스트라이드가 1면 한칸씩 이동하며 필터를 적용
- 스트라이드가 2면 두칸씩 이동하며 필터를 적용 
- 스트라이드를 키우면 출력 크기는 작아짐 

- 위의 두 관계로 출력의 크기를 식으로 표현 할 수 있는데...
- 입력의 크기(H,W), 필터의 크기(FH,FW), 출력의 크기(OH,OW), 패딩(P), 스트라이드(S)라고 하면
-> OH(출력의 높이) = (H+2P-FH)/S +1
-> OW(출력의 넓이) = (W+2P-FW)/S +1
- 여기서 중요한 것은 OH,OW의 값이 정수로 나눠떨어져야함!!
- 안그럴 경우 가까운 정수로 반올림하거나 오류를 내는 등의 대응 필요

데이터가 3차원일 경우
- 위의 경우는 데이터가 2차원일 경우였다면
- 2차원 예) 4x4입력 x 3x3필터 
- 3차원 예) 4x4x3입력 x 3x3x(?)
- 여기서 ?는 입력 데이터의 채널 수 3 
- 필터의 수 = 입력 데이터의 채널 수
- 결과는 각 (입력데이터 x 필터)의 합을 결과물 한칸에 저장  
- 예) 4x4x3 x 3x3x3 -> 2x2 (2x2x3에서 나온 결과물을 다 합해서 2x2한층으로 만들어줌)
